---
title: "The GenAI divide report: Scrutiny, hype, and the reality of AI adoption"
description: "An analysis of the controversial MIT NANDA report on AI ROI, contrasting its claims with critical perspectives and exploring the real challenges of enterprise AI adoption."
date: 2025-08-27
tags: [technology, ai, strategy, critical-thinking]
---

Two weeks ago, a report titled "The GenAI Divide," produced in collaboration with MIT's Project NANDA, made significant waves. Its headline claim—that 95% of enterprise Generative AI initiatives yield zero financial return—was quickly amplified by news outlets and fuelled discussions about a potential AI bubble.

However, a closer look at the report and the subsequent analysis from industry experts reveals a more nuanced story. The debate it sparked offers valuable lessons on technological adoption, academic rigour, and the organisational challenges that truly define success with AI.

### A critical examination of the report

Wharton Professor [Kevin Werbach provided a sharp critique](https://www.linkedin.com/posts/kevinwerbach_state-of-ai-in-business-2025-activity-7365026841759215616-SQWD) of the report's methodology and conclusions. He argues that the document is "deeply problematic" and that its most striking claim lacks clear evidence within the report itself.

> The "MIT report" which made a big splash this week, finding few generative AI deployments generate any returns, is deeply problematic. The incident is, frankly, a great example of confirmation bias.

Kevin points out several key issues:
*   **Unsubstantiated Claims:** The "95% getting zero return" figure is stated in the executive summary but is not clearly supported by data in the rest of the document. The methodology, based on interviews with 52 organisations and surveys with 153 leaders, is not detailed enough to validate such a specific, impactful claim.
*   **Misleading Association:** He notes the report was produced "in collaboration with Project NANDA out of MIT," questioning the level of involvement from MIT's core faculty and researchers. This association lent the report a degree of credibility that its contents may not warrant.
*   **Vague Definitions:** The report defines "unsuccessful" deployment in a way that does not explicitly mean "zero returns," creating ambiguity.

Kevin suggests that the report's authors may have lacked academic research rigour, and its findings were seized upon by sceptics looking to confirm their biases.

### Beyond the bubble talk

In his Substack newsletter, [Jonas Braadbaart offers a different perspective](https://substack.com/inbox/post/171484370). While acknowledging the report and the "bubble talk" it generated, he argues that for business owners and operators, the focus should be elsewhere. Jonas contends that we are still in the very early stages of AI adoption, comparable to the internet in 1998.

He cleverly uses the report's own data to highlight what he sees as the real issue. When interviewees were asked about the likely causes for pilot failures, the top reasons were not technical.

> Most of the challenges faced by these pilots were organizational—not technological.

Jonas points to a disconnect between IT and business teams, poor user experience, and a failure to set the right context for users as the primary culprits. The problem is not that the technology is failing, but that organisations are failing to adapt their processes and culture to leverage it effectively.

### Personal reflection

Connecting the perspectives of Kevin Werbach and Jonas Braadbaart provides a comprehensive view. Kevin rightly scrutinises the report's sensationalist claims and questionable methodology, reminding us to be critical of sources, even those with prestigious affiliations. Jonas, on the other hand, looks past the headline to extract a practical insight: the friction in AI adoption is more organisational than technological.

I believe there is immense value to be gained from AI, but it is not a magic wand. The NANDA report, despite its flaws, inadvertently highlights this truth. The focus on "agentic AI" and other technical solutions within the report feels like a distraction from the core challenge. Real, sustainable returns will not come from a slightly better model or a new marketing term. They will come from fundamentally rethinking and adapting our ways of working.

Success requires integrating these new tools into our existing workflows in a thoughtful way, which means changing processes that have been in place for years. It demands that we move beyond the hype and critically assess how this technology can solve specific, real-world problems within our businesses. The real "GenAI divide" is not between companies getting returns and those getting zero; it is between organisations that understand this and those that are still waiting for a plug-and-play solution.